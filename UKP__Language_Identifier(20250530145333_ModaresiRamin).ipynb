{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744e1e28",
   "metadata": {},
   "source": [
    "## 1) Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dd8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b396c87",
   "metadata": {},
   "source": [
    "## 2) Dataset Setup Instructions\n",
    "\n",
    "Before executing the following cells, you need to download the dataset from the Tatoeba Project:\n",
    "\n",
    "### Step 1: Download the Dataset\n",
    "\n",
    "- Go to: https://downloads.tatoeba.org/exports/sentences.tar.bz2\n",
    "- Download the compressed file (approximately 194 MB)\n",
    "- Extract the archive - you'll get a file called sentences.csv (approximately 678 MB)\n",
    "\n",
    "### Step 2: Place the File\n",
    "\n",
    "Put the extracted sentences.csv file in the same directory as this notebook\n",
    "\n",
    "The file structure should look like:\n",
    "\n",
    "```\n",
    "your-project-folder/\n",
    "├── language_id.ipynb  # This notebook\n",
    "└── sentences.csv      # The dataset\n",
    "```\n",
    "\n",
    "### What's in the Dataset\n",
    "\n",
    "- Over 14 million sentences in many different languages\n",
    "- Tab-separated format with columns: ID, Language Code, Sentence\n",
    "- Languages are coded using ISO 639-3 format (e.g., 'eng' for English)\n",
    "- Highly imbalanced - some languages have millions of sentences, others just a few hundred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0f4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 12,775,409\n",
      "Available languages: 423\n",
      "Sample languages:\n",
      "eng    1978526\n",
      "rus    1127493\n",
      "ita     918424\n",
      "epo     789476\n",
      "kab     764433\n",
      "Name: Lang, dtype: int64\n",
      "\n",
      "Dataset Overview:\n",
      "Shape: (12775409, 3)\n",
      "Columns: ['ID', 'Lang', 'Sentence']\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "file_path = \"sentences.csv\"\n",
    "\n",
    "try:\n",
    "    # The dataset is tab-separated with no header, so we define column names\n",
    "    df = pd.read_csv(file_path, sep = \"\\t\", header = None, names = [\"ID\", \"Lang\", \"Sentence\"])\n",
    "    print(f\"Total rows: {len(df):,}\")\n",
    "    print(f\"Available languages: {df['Lang'].nunique()}\")\n",
    "    print(f\"Sample languages:\\n{df['Lang'].value_counts().head()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'sentences.csv' file not found!\")\n",
    "    raise\n",
    "\n",
    "# Show basic dataset information\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7c123",
   "metadata": {},
   "source": [
    "## 3) Filter, Sample, and Prepare Training Data\n",
    "\n",
    "This step processes the raw dataset into training-ready format:\n",
    "- Filters to target languages (13 diverse languages)\n",
    "- Samples equal sentences per language (balanced dataset)\n",
    "- Maps language codes (ISO 639-3 → ISO 639-1)\n",
    "- Creates dictionary structure for model training\n",
    "\n",
    "The balanced approach ensures no language dominates during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6482163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after filtering: 7,621,439\n",
      "Language distribution:\n",
      "eng (English): 1,978,526 sentences\n",
      "deu (German): 721,388 sentences\n",
      "fra (French): 666,311 sentences\n",
      "spa (Spanish): 414,431 sentences\n",
      "ita (Italian): 918,424 sentences\n",
      "por (Portuguese): 436,229 sentences\n",
      "rus (Russian): 1,127,493 sentences\n",
      "jpn (Japanese): 245,837 sentences\n",
      "cmn (Chinese): 77,801 sentences\n",
      "tur (Turkish): 738,242 sentences\n",
      "pol (Polish): 131,575 sentences\n",
      "kor (Korean): 13,984 sentences\n",
      "fin (Finnish): 151,198 sentences\n",
      "\n",
      "Will proceed with 13 languages\n",
      "\n",
      "Sampling 800 sentences per language.\n",
      "Final sample distribution:\n",
      "eng (English): 800\n",
      "deu (German): 800\n",
      "fra (French): 800\n",
      "spa (Spanish): 800\n",
      "ita (Italian): 800\n",
      "por (Portuguese): 800\n",
      "rus (Russian): 800\n",
      "jpn (Japanese): 800\n",
      "cmn (Chinese): 800\n",
      "tur (Turkish): 800\n",
      "pol (Polish): 800\n",
      "kor (Korean): 800\n",
      "fin (Finnish): 800\n"
     ]
    }
   ],
   "source": [
    "# List of target languages we want to include\n",
    "target_languages = [\n",
    "    \"eng\",  # English\n",
    "    \"deu\",  # German  \n",
    "    \"fra\",  # French\n",
    "    \"spa\",  # Spanish\n",
    "    \"ita\",  # Italian\n",
    "    \"por\",  # Portuguese\n",
    "    \"rus\",  # Russian\n",
    "    \"jpn\",  # Japanese\n",
    "    \"cmn\",  # Chinese (Mandarin)\n",
    "    \"tur\",  # Turkish\n",
    "    \"pol\",  # Polish\n",
    "    \"kor\",  # Korean\n",
    "    \"fin\"   # Finnish\n",
    "]\n",
    "\n",
    "# Friendly names for display\n",
    "language_names = {\n",
    "    \"eng\": \"English\", \n",
    "    \"deu\": \"German\", \n",
    "    \"fra\": \"French\", \n",
    "    \"spa\": \"Spanish\",\n",
    "    \"ita\": \"Italian\", \n",
    "    \"por\": \"Portuguese\", \n",
    "    \"rus\": \"Russian\", \n",
    "    \"jpn\": \"Japanese\", \n",
    "    \"cmn\": \"Chinese\", \n",
    "    \"tur\": \"Turkish\", \n",
    "    \"pol\": \"Polish\", \n",
    "    \"kor\": \"Korean\", \n",
    "    \"fin\": \"Finnish\"}\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_filtered = df[df[\"Lang\"].isin(target_languages)]\n",
    "\n",
    "print(f\"Total rows after filtering: {len(df_filtered):,}\")\n",
    "print(f\"Language distribution:\")\n",
    "\n",
    "# Check availability and show counts\n",
    "available_languages = []\n",
    "for lang in target_languages:\n",
    "    count = len(df_filtered[df_filtered[\"Lang\"] == lang])\n",
    "    if count > 0:\n",
    "        available_languages.append(lang)\n",
    "        print(f\"{lang} ({language_names[lang]}): {count:,} sentences\")\n",
    "    else:\n",
    "        print(f\"{lang} ({language_names[lang]}): Not available\")\n",
    "\n",
    "# Update target languages to only include available ones\n",
    "target_languages = available_languages\n",
    "print(f\"\\nWill proceed with {len(target_languages)} languages\")\n",
    "\n",
    "# Determine sample size based on smallest language\n",
    "min_samples = min([len(df_filtered[df_filtered[\"Lang\"] == lang]) for lang in target_languages])\n",
    "sample_size = min(800, min_samples)\n",
    "\n",
    "print(f\"\\nSampling {sample_size} sentences per language.\")\n",
    "\n",
    "samples = (df_filtered[df_filtered[\"Lang\"].isin(target_languages)]\n",
    "           .groupby(\"Lang\")\n",
    "           .apply(lambda x: x.sample(n=min(sample_size, len(x)), random_state=42))\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "# Check final sample counts\n",
    "print(\"Final sample distribution:\")\n",
    "sample_counts = samples[\"Lang\"].value_counts().sort_index()\n",
    "for lang in target_languages:\n",
    "    count = sample_counts.get(lang, 0)\n",
    "    print(f\"{lang} ({language_names[lang]}): {count}\")\n",
    "\n",
    "# Print one example per language (first 6 to avoid too much output)\n",
    "# print(f\"\\nSample sentences:\")\n",
    "# for lang in target_languages[:6]:\n",
    "#     if lang in samples[\"Lang\"].values:\n",
    "#         sample_text = samples[samples[\"Lang\"] == lang][\"Sentence\"].iloc[0]\n",
    "#         print(f\"{lang}: {sample_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7ffe8",
   "metadata": {},
   "source": [
    "## 4) Save Filtered Dataset\n",
    "\n",
    "The processed dataset is saved to a new CSV file.\n",
    "\n",
    "The saved file `filtered_sentences.csv` will be used in the next steps for training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09266325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as 'filtered_sentences.csv'\n",
      "Total rows saved: 10,400\n",
      "File size: 571.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Save the processed dataset\n",
    "output_file = \"filtered_sentences.csv\"\n",
    "samples.to_csv(output_file, index = False)\n",
    "\n",
    "print(f\"Filtered dataset saved as '{output_file}'\")\n",
    "print(f\"Total rows saved: {len(samples):,}\")\n",
    "print(f\"File size: {os.path.getsize(output_file) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a3faf",
   "metadata": {},
   "source": [
    "## 5) Load and Prepare Training Data\n",
    "\n",
    "This function reads the filtered dataset and organizes it for model training:\n",
    "\n",
    "- **Language Code Mapping**: Converts ISO 639-3 codes (e.g., 'eng') to shorter ISO 639-1 codes (e.g., 'en')\n",
    "- **Data Structure**: Creates a dictionary where keys are language codes and values are lists of sentences\n",
    "- **Statistics**: Shows the number of sentences and average length per language\n",
    "\n",
    "The output dictionary is ready to be fed directly into the `LanguageIdentifier.train()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "254401f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(filepath: str) -> Dict[str, List[str]]:\n",
    "    print(f\"Loading training data from {filepath}\")\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Clean and normalize language codes\n",
    "    df['Lang'] = df['Lang'].astype(str).str.strip().str.lower()\n",
    "    \n",
    "    # Extended language mapping (ISO 639-3 to ISO 639-1 where possible)\n",
    "    lang_map = {\n",
    "        'eng': 'en', \n",
    "        'deu': 'de', \n",
    "        'fra': 'fr', \n",
    "        'spa': 'es',\n",
    "        'ita': 'it', \n",
    "        'por': 'pt', \n",
    "        'rus': 'ru', \n",
    "        'jpn': 'ja',\n",
    "        'cmn': 'zh', \n",
    "        'tur': 'tr', \n",
    "        'pol': 'pl', \n",
    "        'kor': 'ko', \n",
    "        'fin': 'fi'}\n",
    "    \n",
    "    df['Lang'] = df['Lang'].map(lang_map)\n",
    "    \n",
    "    print(f\"Languages found: {sorted(df['Lang'].unique())}\")\n",
    "    \n",
    "    # Drop rows where mapping failed\n",
    "    df = df.dropna(subset=['Lang'])\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    training_data = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        training_data[row['Lang']].append(row['Sentence'])\n",
    "    \n",
    "    # Convert to regular dict and show statistics\n",
    "    training_data = dict(training_data)\n",
    "    print(f\"Training data prepared for {len(training_data)} languages:\")\n",
    "    for lang, texts in sorted(training_data.items()):\n",
    "        print(f\"{lang}: {len(texts):,} sentences\")\n",
    "        # Show average sentence length\n",
    "        avg_length = sum(len(text) for text in texts) / len(texts)\n",
    "        print(f\"Average length: {avg_length:.1f} characters\")\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85555771",
   "metadata": {},
   "source": [
    "## 6) Define the Language Identifier Class\n",
    "\n",
    "This class implements the core language detection algorithm using character n-gram profiles and rank-order distance comparison.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "- **Training**: Extract character n-grams from texts, build frequency profiles for each language\n",
    "- **Prediction**: Compare input text's n-gram profile against all language profiles using distance metrics\n",
    "- **Parameters**: Uses 3-character n-grams and top 300 features per language by default\n",
    "\n",
    "The algorithm identifies languages by finding the closest matching n-gram profile based on statistical similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65f6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Language Identification using Character N-gram Profiles\n",
    "Based on the rank-order statistical method described in:\n",
    "Cavnar, W. B., & Trenkle, J. M. (1994). N-gram-based text categorization.\n",
    "Proceedings of SDAIR-94, 3rd annual symposium on document analysis and information retrieval.\n",
    "\"\"\"\n",
    "\n",
    "class LanguageIdentifier:\n",
    "    def __init__(self, n_gram_size: int = 3, max_features: int = 300):\n",
    "        \"\"\"\n",
    "        Initialize the Language Identifier\n",
    "        \n",
    "        Args:\n",
    "            n_gram_size: Size of character n-grams (default: 3)\n",
    "            max_features: Maximum number of n-gram features to use per language\n",
    "        \"\"\"\n",
    "        self.n_gram_size = n_gram_size\n",
    "        self.max_features = max_features\n",
    "        self.language_profiles = {}\n",
    "        self.trained = False\n",
    "    \n",
    "    def _extract_ngrams(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract character n-grams from text\"\"\"\n",
    "        # Clean and normalize text\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text.lower())  # remove punctuation\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())      # normalize whitespace\n",
    "        \n",
    "        # Add padding to capture beginning and end of text\n",
    "        padded_text = '_' * (self.n_gram_size - 1) + text + '_' * (self.n_gram_size - 1)\n",
    "        \n",
    "        # Extract n-grams\n",
    "        ngrams = []\n",
    "        for i in range(len(padded_text) - self.n_gram_size + 1):\n",
    "            ngrams.append(padded_text[i:i + self.n_gram_size])\n",
    "        \n",
    "        return ngrams\n",
    "    \n",
    "    def _create_profile(self, ngrams: List[str]) -> Dict[str, int]:\n",
    "        \"\"\"Create frequency profile from n-grams\"\"\"\n",
    "        counter = Counter(ngrams)\n",
    "        # Return top features ranked by frequency\n",
    "        return dict(counter.most_common(self.max_features))\n",
    "    \n",
    "    def train(self, training_data: Dict[str, List[str]]):\n",
    "        \"\"\"\n",
    "        training_data: Dict with language codes as keys and list of texts as values\n",
    "        \n",
    "        building n-gram profiles for each language in the training data and stores them\n",
    "        \"\"\"\n",
    "        for language, texts in training_data.items():\n",
    "            print(f\"Processing {language} - ({len(texts)} texts)\")\n",
    "            all_ngrams = []\n",
    "            \n",
    "            for text in texts:\n",
    "                ngrams = self._extract_ngrams(text)\n",
    "                all_ngrams.extend(ngrams)\n",
    "            \n",
    "            # Create language profile\n",
    "            self.language_profiles[language] = self._create_profile(all_ngrams)\n",
    "            print(f\"Created profile with {len(self.language_profiles[language])} n-grams\")\n",
    "        \n",
    "        self.trained = True\n",
    "        print(f\"Training completed for {len(self.language_profiles)} languages\")\n",
    "    \n",
    "    def _calculate_distance(self, doc_profile: Dict[str, int], lang_profile: Dict[str, int]) -> float:\n",
    "        \"\"\"\n",
    "        Compute the rank-order distance between a document's n-gram profile and a known language profile.\n",
    "        (`doc_profile` and `lang_profile` are dictionaries containing the top n-grams for the input text \n",
    "        and each known language, ranked by frequency.)\n",
    "\n",
    "        The distance is calculated by comparing the rank positions of shared n-grams.\n",
    "        For n-grams missing in the language profile, a fixed penalty is added.\n",
    "        Lower distance indicates higher similarity between the profiles.\n",
    "        \"\"\"\n",
    "        distance = 0\n",
    "        \n",
    "        # Create rank dictionaries\n",
    "        doc_ranks = {ngram: rank for rank, (ngram, _) in enumerate(doc_profile.items())}\n",
    "        lang_ranks = {ngram: rank for rank, (ngram, _) in enumerate(lang_profile.items())}\n",
    "        \n",
    "        # Calculate distance\n",
    "        for ngram in doc_ranks:\n",
    "            if ngram in lang_ranks:\n",
    "                distance += abs(doc_ranks[ngram] - lang_ranks[ngram])\n",
    "            else:\n",
    "                # Penalty for n-grams not in language profile\n",
    "                distance += self.max_features\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def identify_language(self, text: str, return_scores: bool = False):\n",
    "        \"\"\"\n",
    "        Identify the language of given text\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to identify\n",
    "            return_scores: If True, returns (language, scores_dict)\n",
    "        \n",
    "        Returns:\n",
    "            Detected language code or tuple with scores if return_scores=True\n",
    "        \"\"\"\n",
    "        if not self.trained:\n",
    "            raise ValueError(\"Model must be trained before prediction\")\n",
    "        \n",
    "        # Extract n-grams and create profile\n",
    "        ngrams = self._extract_ngrams(text)\n",
    "        doc_profile = self._create_profile(ngrams)\n",
    "        \n",
    "        # Calculate distances to all language profiles\n",
    "        distances = {}\n",
    "        for language, lang_profile in self.language_profiles.items():\n",
    "            distances[language] = self._calculate_distance(doc_profile, lang_profile)\n",
    "        \n",
    "        # Find language with minimum distance\n",
    "        predicted_language = min(distances, key = distances.get)\n",
    "        \n",
    "        if return_scores:\n",
    "            # Convert distances to similarity scores (lower distance = higher similarity)\n",
    "            max_distance = max(distances.values()) if distances.values() else 1\n",
    "            scores = {lang: 1 - (dist / max_distance) for lang, dist in distances.items()}\n",
    "            return predicted_language, scores\n",
    "        \n",
    "        return predicted_language\n",
    "\n",
    "# print(\"LanguageIdentifier class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790600fd",
   "metadata": {},
   "source": [
    "## 7) Initialize and Train the Model\n",
    "\n",
    "Here we create an instance of `LanguageIdentifier`, set it to use 3-character n-grams,  \n",
    "and train it on the filtered dataset using the top 300 most frequent n-grams per language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229ebe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from filtered_sentences.csv\n",
      "Languages found: ['de', 'en', 'es', 'fi', 'fr', 'it', 'ja', 'ko', 'pl', 'pt', 'ru', 'tr', 'zh']\n",
      "Training data prepared for 13 languages:\n",
      "de: 800 sentences\n",
      "Average length: 46.7 characters\n",
      "en: 800 sentences\n",
      "Average length: 41.9 characters\n",
      "es: 800 sentences\n",
      "Average length: 38.7 characters\n",
      "fi: 800 sentences\n",
      "Average length: 35.4 characters\n",
      "fr: 800 sentences\n",
      "Average length: 40.9 characters\n",
      "it: 800 sentences\n",
      "Average length: 34.7 characters\n",
      "ja: 800 sentences\n",
      "Average length: 18.1 characters\n",
      "ko: 800 sentences\n",
      "Average length: 15.3 characters\n",
      "pl: 800 sentences\n",
      "Average length: 32.8 characters\n",
      "pt: 800 sentences\n",
      "Average length: 43.5 characters\n",
      "ru: 800 sentences\n",
      "Average length: 33.0 characters\n",
      "tr: 800 sentences\n",
      "Average length: 33.7 characters\n",
      "zh: 800 sentences\n",
      "Average length: 11.3 characters\n",
      "N-gram size: 3\n",
      "Max features per language: 300\n",
      "\n",
      "==================================================\n",
      "Processing zh - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing de - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing en - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing fi - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing fr - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing it - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing ja - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing ko - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing pl - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing pt - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing ru - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing es - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Processing tr - (800 texts)\n",
      "Created profile with 300 n-grams\n",
      "Training completed for 13 languages\n"
     ]
    }
   ],
   "source": [
    "training_data = load_training_data(\"filtered_sentences.csv\")\n",
    "\n",
    "# Initialize the identifier with optimal parameters\n",
    "identifier = LanguageIdentifier(n_gram_size = 3, max_features = 300)\n",
    "\n",
    "print(f\"N-gram size: {identifier.n_gram_size}\")\n",
    "print(f\"Max features per language: {identifier.max_features}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "identifier.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d8777",
   "metadata": {},
   "source": [
    "## 8) Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230fd4e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation with pre-trained model\n",
      "STARTING EVALUATION\n",
      "==================================================\n",
      "Using pre-trained model with 13 languages\n",
      "Languages: de, en, es, fi, fr, it, ja, ko, pl, pt, ru, tr, zh\n",
      "Available test samples: 10400\n",
      "Languages in test data: ['de', 'en', 'es', 'fi', 'fr', 'it', 'ja', 'ko', 'pl', 'pt', 'ru', 'tr', 'zh']\n",
      "Test set size: 3120 samples\n",
      "Test set distribution:\n",
      "de: 240 samples\n",
      "en: 240 samples\n",
      "es: 240 samples\n",
      "fi: 240 samples\n",
      "fr: 240 samples\n",
      "it: 240 samples\n",
      "ja: 240 samples\n",
      "ko: 240 samples\n",
      "pl: 240 samples\n",
      "pt: 240 samples\n",
      "ru: 240 samples\n",
      "tr: 240 samples\n",
      "zh: 240 samples\n",
      "\n",
      "Evaluating model on 3120 test samples\n",
      "Evaluation completed!\n",
      "Accuracy: 0.968 (96.8%)\n",
      "F1-Score: 0.968\n",
      "Average Confidence: 0.340\n",
      "\n",
      "DETAILED CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          de      0.975     0.983     0.979       240\n",
      "          en      0.959     0.979     0.969       240\n",
      "          es      0.919     0.896     0.907       240\n",
      "          fi      0.979     0.992     0.986       240\n",
      "          fr      0.951     0.979     0.965       240\n",
      "          it      0.919     0.942     0.930       240\n",
      "          ja      1.000     0.992     0.996       240\n",
      "          ko      1.000     0.979     0.989       240\n",
      "          pl      0.996     0.967     0.981       240\n",
      "          pt      0.912     0.912     0.912       240\n",
      "          ru      1.000     1.000     1.000       240\n",
      "          tr      0.996     0.958     0.977       240\n",
      "          zh      0.976     1.000     0.988       240\n",
      "\n",
      "    accuracy                          0.968      3120\n",
      "   macro avg      0.968     0.968     0.968      3120\n",
      "weighted avg      0.968     0.968     0.968      3120\n",
      "\n",
      "\n",
      "PER-LANGUAGE ANALYSIS:\n",
      "----------------------------------------\n",
      "\n",
      "DE:\n",
      "Accuracy: 0.983 (240 samples)\n",
      "Avg confidence (correct): 0.429\n",
      "Avg confidence (incorrect): 0.350\n",
      "Most confused with: {'en': 3, 'fr': 1}\n",
      "\n",
      "EN:\n",
      "Accuracy: 0.979 (240 samples)\n",
      "Avg confidence (correct): 0.406\n",
      "Avg confidence (incorrect): 0.329\n",
      "Most confused with: {'de': 3, 'it': 1, 'fr': 1}\n",
      "\n",
      "ES:\n",
      "Accuracy: 0.896 (240 samples)\n",
      "Avg confidence (correct): 0.389\n",
      "Avg confidence (incorrect): 0.353\n",
      "Most confused with: {'pt': 11, 'it': 9, 'fr': 3}\n",
      "\n",
      "FI:\n",
      "Accuracy: 0.992 (240 samples)\n",
      "Avg confidence (correct): 0.381\n",
      "Avg confidence (incorrect): 0.283\n",
      "Most confused with: {'de': 1, 'pt': 1}\n",
      "\n",
      "FR:\n",
      "Accuracy: 0.979 (240 samples)\n",
      "Avg confidence (correct): 0.423\n",
      "Avg confidence (incorrect): 0.351\n",
      "Most confused with: {'it': 2, 'de': 1, 'pt': 1}\n",
      "\n",
      "IT:\n",
      "Accuracy: 0.942 (240 samples)\n",
      "Avg confidence (correct): 0.396\n",
      "Avg confidence (incorrect): 0.325\n",
      "Most confused with: {'es': 6, 'pt': 5, 'fr': 2}\n",
      "\n",
      "JA:\n",
      "Accuracy: 0.992 (240 samples)\n",
      "Avg confidence (correct): 0.224\n",
      "Avg confidence (incorrect): 0.000\n",
      "Most confused with: {'zh': 2}\n",
      "\n",
      "KO:\n",
      "Accuracy: 0.979 (240 samples)\n",
      "Avg confidence (correct): 0.233\n",
      "Avg confidence (incorrect): 0.043\n",
      "Most confused with: {'zh': 4, 'pt': 1}\n",
      "\n",
      "PL:\n",
      "Accuracy: 0.967 (240 samples)\n",
      "Avg confidence (correct): 0.338\n",
      "Avg confidence (incorrect): 0.290\n",
      "Most confused with: {'it': 2, 'pt': 2, 'tr': 1}\n",
      "\n",
      "PT:\n",
      "Accuracy: 0.912 (240 samples)\n",
      "Avg confidence (correct): 0.408\n",
      "Avg confidence (incorrect): 0.343\n",
      "Most confused with: {'es': 11, 'it': 5, 'fr': 3}\n",
      "\n",
      "RU:\n",
      "Accuracy: 1.000 (240 samples)\n",
      "Avg confidence (correct): 0.318\n",
      "\n",
      "TR:\n",
      "Accuracy: 0.958 (240 samples)\n",
      "Avg confidence (correct): 0.358\n",
      "Avg confidence (incorrect): 0.216\n",
      "Most confused with: {'fi': 3, 'es': 2, 'en': 2}\n",
      "\n",
      "ZH:\n",
      "Accuracy: 1.000 (240 samples)\n",
      "Avg confidence (correct): 0.152\n",
      "\n",
      "CONFUSION MATRIX ANALYSIS\n",
      "========================================\n",
      "Confusion Matrix:\n",
      "     de   en   es   fi   fr   it   ja   ko   pl   pt   ru   tr   zh\n",
      "de  236    3    0    0    1    0    0    0    0    0    0    0    0\n",
      "en    3  235    0    0    1    1    0    0    0    0    0    0    0\n",
      "es    0    1  215    0    3    9    0    0    1   11    0    0    0\n",
      "fi    1    0    0  238    0    0    0    0    0    1    0    0    0\n",
      "fr    1    0    0    1  235    2    0    0    0    1    0    0    0\n",
      "it    0    1    6    0    2  226    0    0    0    5    0    0    0\n",
      "ja    0    0    0    0    0    0  238    0    0    0    0    0    2\n",
      "ko    0    0    0    0    0    0    0  235    0    1    0    0    4\n",
      "pl    0    1    0    1    1    2    0    0  232    2    0    1    0\n",
      "pt    0    2   11    0    3    5    0    0    0  219    0    0    0\n",
      "ru    0    0    0    0    0    0    0    0    0    0  240    0    0\n",
      "tr    1    2    2    3    1    1    0    0    0    0    0  230    0\n",
      "zh    0    0    0    0    0    0    0    0    0    0    0    0  240\n",
      "\n",
      "MOST CONFUSED LANGUAGE PAIRS:\n",
      "-----------------------------------\n",
      "  es → pt: 11 errors (4.6%)\n",
      "  pt → es: 11 errors (4.6%)\n",
      "  es → it: 9 errors (3.8%)\n",
      "  it → es: 6 errors (2.5%)\n",
      "  it → pt: 5 errors (2.1%)\n",
      "  pt → it: 5 errors (2.1%)\n",
      "  ko → zh: 4 errors (1.7%)\n",
      "  de → en: 3 errors (1.2%)\n",
      "\n",
      "ERROR ANALYSIS\n",
      "==============================\n",
      "Total errors: 101/3120 (3.2%)\n",
      "\n",
      "Sample errors (showing 5):\n",
      "------------------------------------------------------------\n",
      "1. TRUE: DE | PRED: EN | CONF: 0.530\n",
      "Text (16 chars): Ist Tom an Bord?\n",
      "\n",
      "2. TRUE: IT | PRED: PT | CONF: 0.529\n",
      "Text (23 chars): Tom sta partendo, vero?\n",
      "\n",
      "3. TRUE: ES | PRED: PT | CONF: 0.512\n",
      "Text (21 chars): Tom nos odia a todos.\n",
      "\n",
      "4. TRUE: EN | PRED: DE | CONF: 0.502\n",
      "Text (16 chars): Tom is underage.\n",
      "\n",
      "5. TRUE: PT | PRED: FR | CONF: 0.500\n",
      "Text (11 chars): Entre, Tom.\n",
      "\n",
      "ERROR PATTERNS:\n",
      "--------------------\n",
      "Average error text length: 21.2 chars\n",
      "Shortest error text: 4 chars\n",
      "Longest error text: 57 chars\n",
      "Results saved to evaluation_results.json\n",
      "\n",
      "EVALUATION COMPLETED!\n",
      "Final Results: Accuracy=0.968, F1=0.968\n"
     ]
    }
   ],
   "source": [
    "class EfficientEvaluation:\n",
    "    \n",
    "    def __init__(self, trained_identifier, test_size = 0.2, random_state = 42):\n",
    "        self.identifier = trained_identifier\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.results = {}\n",
    "        \n",
    "        # Verify the model is trained\n",
    "        if not self.identifier.trained:\n",
    "            raise ValueError(\"The provided identifier must be already trained!\")\n",
    "        \n",
    "        print(f\"Using pre-trained model with {len(self.identifier.language_profiles)} languages\")\n",
    "        print(f\"Languages: {', '.join(sorted(self.identifier.language_profiles.keys()))}\")\n",
    "    \n",
    "    def prepare_test_data(self, data_path = \"filtered_sentences.csv\"):        \n",
    "        # Load data\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Language mapping (same as training)\n",
    "        lang_map = {\n",
    "            'eng': 'en', \n",
    "            'deu': 'de', \n",
    "            'fra': 'fr', \n",
    "            'spa': 'es',\n",
    "            'ita': 'it', \n",
    "            'por': 'pt', \n",
    "            'rus': 'ru', \n",
    "            'jpn': 'ja',\n",
    "            'cmn': 'zh', \n",
    "            'tur': 'tr', \n",
    "            'pol': 'pl', \n",
    "            'kor': 'ko', \n",
    "            'fin': 'fi'\n",
    "        }\n",
    "        \n",
    "        df['Lang'] = df['Lang'].map(lang_map)\n",
    "        df = df.dropna(subset=['Lang'])\n",
    "        \n",
    "        # Only keep languages that our model supports\n",
    "        model_languages = set(self.identifier.language_profiles.keys())\n",
    "        df = df[df['Lang'].isin(model_languages)]\n",
    "        \n",
    "        print(f\"Available test samples: {len(df)}\")\n",
    "        print(f\"Languages in test data: {sorted(df['Lang'].unique())}\")\n",
    "        \n",
    "        # Create train/test split for evaluation\n",
    "        X = df['Sentence'].values\n",
    "        y = df['Lang'].values\n",
    "        \n",
    "        # Use stratified split to maintain class balance\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = self.test_size, stratify = y, random_state = self.random_state)\n",
    "        \n",
    "        print(f\"Test set size: {len(X_test)} samples\")\n",
    "        \n",
    "        # Show test set distribution\n",
    "        test_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "        \n",
    "        print(\"Test set distribution:\")\n",
    "        \n",
    "        for lang, count in test_dist.items():\n",
    "            print(f\"{lang}: {count} samples\")\n",
    "        \n",
    "        return X_test, y_test\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        print(f\"\\nEvaluating model on {len(X_test)} test samples\")\n",
    "        \n",
    "        predictions = []\n",
    "        confidences = []\n",
    "        prediction_scores = []\n",
    "        \n",
    "        # Get predictions for all test samples\n",
    "        for i, text in enumerate(X_test):\n",
    "#             if (i + 1) % 100 == 0:\n",
    "#                 print(f\"Processed {i + 1}/{len(X_test)} samples\")       \n",
    "            try:\n",
    "                pred, scores = self.identifier.identify_language(text, return_scores = True)\n",
    "                predictions.append(pred)\n",
    "                \n",
    "                # Get confidence as max score\n",
    "                max_confidence = max(scores.values()) if scores else 0\n",
    "                confidences.append(max_confidence)\n",
    "                prediction_scores.append(scores)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {i}: {e}\")\n",
    "                predictions.append('unknown')\n",
    "                confidences.append(0.0)\n",
    "                prediction_scores.append({})\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions, average = 'weighted')\n",
    "        \n",
    "        # Store results\n",
    "        self.results = {\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_f1': f1,\n",
    "            'predictions': predictions,\n",
    "            'true_labels': y_test,\n",
    "            'confidences': confidences,\n",
    "            'prediction_scores': prediction_scores,\n",
    "            'test_texts': X_test\n",
    "        }\n",
    "        \n",
    "        print(f\"Evaluation completed!\")\n",
    "        print(f\"Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "        print(f\"F1-Score: {f1:.3f}\")\n",
    "        print(f\"Average Confidence: {np.mean(confidences):.3f}\")\n",
    "        \n",
    "        return accuracy, f1\n",
    "    \n",
    "    def detailed_report(self):\n",
    "        \"\"\"\n",
    "        Generate detailed classification report\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results available. Run evaluate_model first.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nDETAILED CLASSIFICATION REPORT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Overall classification report\n",
    "        report = classification_report(self.results['true_labels'], self.results['predictions'], digits = 3)\n",
    "        print(report)\n",
    "        \n",
    "        # Per-language detailed analysis\n",
    "        print(f\"\\nPER-LANGUAGE ANALYSIS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        languages = sorted(set(self.results['true_labels']))\n",
    "        \n",
    "        for lang in languages:\n",
    "            # Get indices for this language\n",
    "            lang_mask = np.array(self.results['true_labels']) == lang\n",
    "            lang_indices = np.where(lang_mask)[0]\n",
    "            \n",
    "            if len(lang_indices) > 0:\n",
    "                lang_true = np.array(self.results['true_labels'])[lang_indices]\n",
    "                lang_pred = np.array(self.results['predictions'])[lang_indices]\n",
    "                lang_conf = np.array(self.results['confidences'])[lang_indices]\n",
    "                \n",
    "                # Calculate metrics\n",
    "                lang_accuracy = accuracy_score(lang_true, lang_pred)\n",
    "                correct_mask = lang_true == lang_pred\n",
    "                correct_conf = lang_conf[correct_mask]\n",
    "                incorrect_conf = lang_conf[~correct_mask]\n",
    "                \n",
    "                print(f\"\\n{lang.upper()}:\")\n",
    "                print(f\"Accuracy: {lang_accuracy:.3f} ({len(lang_indices)} samples)\")\n",
    "                print(f\"Avg confidence (correct): {np.mean(correct_conf):.3f}\")\n",
    "                if len(incorrect_conf) > 0:\n",
    "                    print(f\"Avg confidence (incorrect): {np.mean(incorrect_conf):.3f}\")\n",
    "                    \n",
    "                    # Show most common errors for this language\n",
    "                    wrong_predictions = lang_pred[~correct_mask]\n",
    "                    if len(wrong_predictions) > 0:\n",
    "                        error_counts = pd.Series(wrong_predictions).value_counts()\n",
    "                        print(f\"Most confused with: {error_counts.head(3).to_dict()}\")\n",
    "    \n",
    "    def confusion_matrix_analysis(self):\n",
    "        \"\"\"Analyze confusion matrix\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results available.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nCONFUSION MATRIX ANALYSIS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        cm = confusion_matrix(self.results['true_labels'], self.results['predictions'])\n",
    "        languages = sorted(set(self.results['true_labels']))\n",
    "        \n",
    "        # Create DataFrame for better visualization\n",
    "        cm_df = pd.DataFrame(cm, index = languages, columns = languages)\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm_df.to_string())\n",
    "        \n",
    "        # Find most problematic pairs\n",
    "        print(f\"\\nMOST CONFUSED LANGUAGE PAIRS:\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        confusion_pairs = []\n",
    "        for i, lang1 in enumerate(languages):\n",
    "            for j, lang2 in enumerate(languages):\n",
    "                if i != j and cm[i][j] > 0:\n",
    "                    confusion_pairs.append((lang1, lang2, cm[i][j]))\n",
    "        \n",
    "        # Sort by confusion count\n",
    "        confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        for lang1, lang2, count in confusion_pairs[:8]:  # Top 8 confusions\n",
    "            total_lang1 = sum(cm[languages.index(lang1)])\n",
    "            error_rate = (count / total_lang1) * 100 if total_lang1 > 0 else 0\n",
    "            print(f\"  {lang1} → {lang2}: {count} errors ({error_rate:.1f}%)\")\n",
    "    \n",
    "    def error_analysis(self, n_examples=10):\n",
    "        \"\"\"Detailed analysis of prediction errors\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results available.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nERROR ANALYSIS\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        # Find all errors\n",
    "        errors = []\n",
    "        for i, (true_lang, pred_lang, text, conf) in enumerate(\n",
    "            zip(self.results['true_labels'], self.results['predictions'], \n",
    "                self.results['test_texts'], self.results['confidences'])\n",
    "        ):\n",
    "            if true_lang != pred_lang:\n",
    "                errors.append({\n",
    "                    'index': i,\n",
    "                    'true_lang': true_lang,\n",
    "                    'pred_lang': pred_lang,\n",
    "                    'text': text,\n",
    "                    'confidence': conf,\n",
    "                    'text_length': len(text)\n",
    "                })\n",
    "        \n",
    "        error_rate = len(errors) / len(self.results['true_labels']) * 100\n",
    "        print(f\"Total errors: {len(errors)}/{len(self.results['true_labels'])} ({error_rate:.1f}%)\")\n",
    "        \n",
    "        if errors:\n",
    "            # Sort errors by confidence (high confidence errors are more interesting)\n",
    "            errors.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "            \n",
    "            print(f\"\\nSample errors (showing {min(n_examples, len(errors))}):\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            for i, error in enumerate(errors[:n_examples], 1):\n",
    "                print(f\"{i}. TRUE: {error['true_lang'].upper()} | PRED: {error['pred_lang'].upper()} | CONF: {error['confidence']:.3f}\")\n",
    "                text_display = error['text'][:120] + \"...\" if len(error['text']) > 120 else error['text']\n",
    "                print(f\"Text ({error['text_length']} chars): {text_display}\")\n",
    "                print()\n",
    "            \n",
    "            # Analyze error patterns\n",
    "            print(f\"ERROR PATTERNS:\")\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "            # Errors by text length\n",
    "            error_lengths = [e['text_length'] for e in errors]\n",
    "            print(f\"Average error text length: {np.mean(error_lengths):.1f} chars\")\n",
    "            print(f\"Shortest error text: {min(error_lengths)} chars\")\n",
    "            print(f\"Longest error text: {max(error_lengths)} chars\")\n",
    "            \n",
    "            # High confidence errors (model was wrong but confident)\n",
    "            high_conf_errors = [e for e in errors if e['confidence'] > 0.8]\n",
    "            if high_conf_errors:\n",
    "                print(f\"High confidence errors (>0.8): {len(high_conf_errors)}\")\n",
    "    \n",
    "    def save_results(self, filepath=\"evaluation_results.json\"):\n",
    "        \"\"\"Save evaluation results\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to save.\")\n",
    "            return\n",
    "        \n",
    "        # Prepare results for JSON serialization\n",
    "        save_data = {\n",
    "            'test_accuracy': float(self.results['test_accuracy']),\n",
    "            'test_f1': float(self.results['test_f1']),\n",
    "            'average_confidence': float(np.mean(self.results['confidences'])),\n",
    "            'total_samples': len(self.results['predictions']),\n",
    "            'model_languages': list(self.identifier.language_profiles.keys()),\n",
    "            'evaluation_timestamp': pd.Timestamp.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        import json\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(save_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Results saved to {filepath}\")\n",
    "\n",
    "# ================================\n",
    "# USAGE EXAMPLE\n",
    "# ================================\n",
    "\n",
    "def run_evaluation(trained_identifier, data_path=\"filtered_sentences.csv\"):\n",
    "\n",
    "    print(\"STARTING EVALUATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize evaluator with pre-trained model\n",
    "    evaluator = EfficientEvaluation(trained_identifier, test_size=0.3)\n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test, y_test = evaluator.prepare_test_data(data_path)\n",
    "    \n",
    "    # Evaluate model\n",
    "    accuracy, f1 = evaluator.evaluate_model(X_test, y_test)\n",
    "    \n",
    "    # Generate detailed reports\n",
    "    evaluator.detailed_report()\n",
    "    evaluator.confusion_matrix_analysis()\n",
    "    evaluator.error_analysis(n_examples=5)\n",
    "    \n",
    "    # Save results\n",
    "    evaluator.save_results()\n",
    "    \n",
    "    print(f\"\\nEVALUATION COMPLETED!\")\n",
    "    print(f\"Final Results: Accuracy={accuracy:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "# Run evaluation using trained model\n",
    "print(\"Starting evaluation with pre-trained model\")\n",
    "evaluator = run_evaluation(identifier, \"filtered_sentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616fb59",
   "metadata": {},
   "source": [
    "## 9) Model Analysis and Statistics\n",
    "\n",
    "In this part, we explore which character n-grams are most frequent in each language profile.  \n",
    "We also calculate overlap between languages to see how similar or different their profiles are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd58c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 15 n-grams for ZH:\n",
      "     1. '⎵⎵我' (199 occurrences)\n",
      "     2. '⎵⎵你' (77 occurrences)\n",
      "     3. '了⎵⎵' (63 occurrences)\n",
      "     4. '⎵⎵他' (62 occurrences)\n",
      "     5. '的⎵⎵' (33 occurrences)\n",
      "     6. '⎵⎵她' (32 occurrences)\n",
      "     7. '嗎⎵⎵' (31 occurrences)\n",
      "     8. '⎵⎵這' (26 occurrences)\n",
      "     9. '⎵⎵这' (25 occurrences)\n",
      "    10. '⎵⎵汤' (24 occurrences)\n",
      "    11. '⎵汤姆' (24 occurrences)\n",
      "    12. '人⎵⎵' (20 occurrences)\n",
      "    13. '⎵⎵那' (19 occurrences)\n",
      "    14. '⎵我們' (18 occurrences)\n",
      "    15. '⎵我们' (17 occurrences)\n",
      "\n",
      " Top 15 n-grams for DE:\n",
      "     1. 'en ' (580 occurrences)\n",
      "     2. 'ich' (510 occurrences)\n",
      "     3. 'er ' (419 occurrences)\n",
      "     4. 'ch ' (404 occurrences)\n",
      "     5. 'ein' (360 occurrences)\n",
      "     6. 'ie ' (291 occurrences)\n",
      "     7. 'n⎵⎵' (287 occurrences)\n",
      "     8. 'sch' (245 occurrences)\n",
      "     9. 'cht' (232 occurrences)\n",
      "    10. 'st ' (230 occurrences)\n",
      "    11. 'en⎵' (228 occurrences)\n",
      "    12. 'in ' (217 occurrences)\n",
      "    13. ' ge' (213 occurrences)\n",
      "    14. ' de' (206 occurrences)\n",
      "    15. ' ei' (200 occurrences)\n",
      "\n",
      " Top 15 n-grams for EN:\n",
      "     1. ' th' (461 occurrences)\n",
      "     2. 'the' (372 occurrences)\n",
      "     3. 'he ' (361 occurrences)\n",
      "     4. ' to' (351 occurrences)\n",
      "     5. 'to ' (255 occurrences)\n",
      "     6. 'ing' (226 occurrences)\n",
      "     7. '⎵⎵t' (220 occurrences)\n",
      "     8. 'n t' (215 occurrences)\n",
      "     9. 'ng ' (204 occurrences)\n",
      "    10. 'is ' (194 occurrences)\n",
      "    11. 'om ' (189 occurrences)\n",
      "    12. 'ed ' (186 occurrences)\n",
      "    13. 'tom' (181 occurrences)\n",
      "    14. '⎵⎵i' (178 occurrences)\n",
      "    15. 'at ' (150 occurrences)\n",
      "\n",
      " Top 15 n-grams for FI:\n",
      "     1. 'a⎵⎵' (262 occurrences)\n",
      "     2. 'en ' (221 occurrences)\n",
      "     3. 'on ' (199 occurrences)\n",
      "     4. ' on' (186 occurrences)\n",
      "     5. 'in ' (185 occurrences)\n",
      "     6. 'n⎵⎵' (177 occurrences)\n",
      "     7. '⎵⎵t' (175 occurrences)\n",
      "     8. 'än ' (155 occurrences)\n",
      "     9. 'an ' (146 occurrences)\n",
      "    10. '⎵⎵m' (145 occurrences)\n",
      "    11. 'min' (145 occurrences)\n",
      "    12. 'inu' (137 occurrences)\n",
      "    13. ' ol' (136 occurrences)\n",
      "    14. 'tä ' (132 occurrences)\n",
      "    15. 'n t' (132 occurrences)\n",
      "\n",
      " Top 15 n-grams for FR:\n",
      "     1. 'es ' (312 occurrences)\n",
      "     2. ' de' (296 occurrences)\n",
      "     3. 'e⎵⎵' (239 occurrences)\n",
      "     4. 'le ' (233 occurrences)\n",
      "     5. 'de ' (233 occurrences)\n",
      "     6. ' pa' (200 occurrences)\n",
      "     7. ' es' (184 occurrences)\n",
      "     8. ' le' (181 occurrences)\n",
      "     9. 'est' (181 occurrences)\n",
      "    10. 'ent' (177 occurrences)\n",
      "    11. 'ne ' (176 occurrences)\n",
      "    12. 'us ' (172 occurrences)\n",
      "    13. ' qu' (166 occurrences)\n",
      "    14. 'e p' (163 occurrences)\n",
      "    15. 're ' (163 occurrences)\n",
      "\n",
      " Top 15 n-grams for IT:\n",
      "     1. 'to ' (231 occurrences)\n",
      "     2. 'o⎵⎵' (226 occurrences)\n",
      "     3. 're ' (224 occurrences)\n",
      "     4. 'a⎵⎵' (213 occurrences)\n",
      "     5. 'on ' (183 occurrences)\n",
      "     6. ' co' (157 occurrences)\n",
      "     7. 'non' (156 occurrences)\n",
      "     8. ' di' (154 occurrences)\n",
      "     9. ' in' (148 occurrences)\n",
      "    10. 'no ' (148 occurrences)\n",
      "    11. 'e⎵⎵' (145 occurrences)\n",
      "    12. 'che' (137 occurrences)\n",
      "    13. 'i⎵⎵' (137 occurrences)\n",
      "    14. 'he ' (128 occurrences)\n",
      "    15. 'di ' (127 occurrences)\n",
      "\n",
      " Top 15 n-grams for JA:\n",
      "     1. 'た⎵⎵' (211 occurrences)\n",
      "     2. '⎵⎵彼' (136 occurrences)\n",
      "     3. 'る⎵⎵' (102 occurrences)\n",
      "     4. 'い⎵⎵' (100 occurrences)\n",
      "     5. 'す⎵⎵' (79 occurrences)\n",
      "     6. 'った⎵' (72 occurrences)\n",
      "     7. '⎵彼は' (68 occurrences)\n",
      "     8. '⎵⎵私' (68 occurrences)\n",
      "     9. 'した⎵' (64 occurrences)\n",
      "    10. 'だ⎵⎵' (62 occurrences)\n",
      "    11. 'よ⎵⎵' (59 occurrences)\n",
      "    12. '⎵⎵こ' (54 occurrences)\n",
      "    13. 'ている' (50 occurrences)\n",
      "    14. 'ない⎵' (50 occurrences)\n",
      "    15. '⎵⎵ト' (47 occurrences)\n",
      "\n",
      " Top 15 n-grams for KO:\n",
      "     1. '다⎵⎵' (310 occurrences)\n",
      "     2. '요⎵⎵' (133 occurrences)\n",
      "     3. '어⎵⎵' (100 occurrences)\n",
      "     4. '⎵⎵그' (85 occurrences)\n",
      "     5. '⎵⎵톰' (76 occurrences)\n",
      "     6. '⎵⎵나' (64 occurrences)\n",
      "     7. '톰은 ' (58 occurrences)\n",
      "     8. '⎵톰은' (57 occurrences)\n",
      "     9. '나는 ' (54 occurrences)\n",
      "    10. '니다⎵' (54 occurrences)\n",
      "    11. '⎵나는' (53 occurrences)\n",
      "    12. '고 있' (42 occurrences)\n",
      "    13. '⎵⎵이' (42 occurrences)\n",
      "    14. '야⎵⎵' (37 occurrences)\n",
      "    15. '⎵⎵우' (35 occurrences)\n",
      "\n",
      " Top 15 n-grams for PL:\n",
      "     1. 'nie' (314 occurrences)\n",
      "     2. 'ie ' (302 occurrences)\n",
      "     3. 'dzi' (159 occurrences)\n",
      "     4. ' ni' (154 occurrences)\n",
      "     5. ' po' (147 occurrences)\n",
      "     6. ' na' (144 occurrences)\n",
      "     7. 'na ' (126 occurrences)\n",
      "     8. 'jes' (119 occurrences)\n",
      "     9. 'est' (118 occurrences)\n",
      "    10. ' je' (117 occurrences)\n",
      "    11. 'e⎵⎵' (116 occurrences)\n",
      "    12. 'ię ' (116 occurrences)\n",
      "    13. ' pr' (114 occurrences)\n",
      "    14. ' si' (110 occurrences)\n",
      "    15. 'się' (105 occurrences)\n",
      "\n",
      " Top 15 n-grams for PT:\n",
      "     1. ' de' (337 occurrences)\n",
      "     2. 'de ' (292 occurrences)\n",
      "     3. 'os ' (270 occurrences)\n",
      "     4. 'que' (269 occurrences)\n",
      "     5. ' qu' (252 occurrences)\n",
      "     6. 'ão ' (237 occurrences)\n",
      "     7. ' co' (217 occurrences)\n",
      "     8. 'o⎵⎵' (211 occurrences)\n",
      "     9. '⎵⎵e' (201 occurrences)\n",
      "    10. 'ue ' (198 occurrences)\n",
      "    11. ' es' (198 occurrences)\n",
      "    12. 'as ' (191 occurrences)\n",
      "    13. 'est' (185 occurrences)\n",
      "    14. ' se' (176 occurrences)\n",
      "    15. 'do ' (170 occurrences)\n",
      "\n",
      " Top 15 n-grams for RU:\n",
      "     1. ' не' (210 occurrences)\n",
      "     2. 'то ' (208 occurrences)\n",
      "     3. 'не ' (207 occurrences)\n",
      "     4. ' по' (159 occurrences)\n",
      "     5. ' на' (138 occurrences)\n",
      "     6. '⎵⎵т' (134 occurrences)\n",
      "     7. 'том' (131 occurrences)\n",
      "     8. 'ть ' (122 occurrences)\n",
      "     9. ' пр' (118 occurrences)\n",
      "    10. 'ом ' (113 occurrences)\n",
      "    11. 'что' (111 occurrences)\n",
      "    12. 'на ' (108 occurrences)\n",
      "    13. 'это' (100 occurrences)\n",
      "    14. ' в ' (98 occurrences)\n",
      "    15. ' чт' (97 occurrences)\n",
      "\n",
      " Top 15 n-grams for ES:\n",
      "     1. ' de' (310 occurrences)\n",
      "     2. ' es' (270 occurrences)\n",
      "     3. 'de ' (242 occurrences)\n",
      "     4. ' qu' (222 occurrences)\n",
      "     5. 'la ' (222 occurrences)\n",
      "     6. 'o⎵⎵' (214 occurrences)\n",
      "     7. 'os ' (211 occurrences)\n",
      "     8. 'que' (207 occurrences)\n",
      "     9. 'no ' (203 occurrences)\n",
      "    10. 'es ' (200 occurrences)\n",
      "    11. 'est' (196 occurrences)\n",
      "    12. 'el ' (186 occurrences)\n",
      "    13. ' la' (185 occurrences)\n",
      "    14. 'ue ' (183 occurrences)\n",
      "    15. 'a⎵⎵' (159 occurrences)\n",
      "\n",
      " Top 15 n-grams for TR:\n",
      "     1. 'tom' (199 occurrences)\n",
      "     2. 'om ' (198 occurrences)\n",
      "     3. ' bi' (196 occurrences)\n",
      "     4. '⎵⎵t' (185 occurrences)\n",
      "     5. '⎵⎵b' (182 occurrences)\n",
      "     6. 'm⎵⎵' (178 occurrences)\n",
      "     7. '⎵to' (169 occurrences)\n",
      "     8. 'bir' (164 occurrences)\n",
      "     9. 'ir ' (157 occurrences)\n",
      "    10. 'r⎵⎵' (153 occurrences)\n",
      "    11. 'yor' (140 occurrences)\n",
      "    12. 'en ' (138 occurrences)\n",
      "    13. ' ya' (126 occurrences)\n",
      "    14. 'in ' (109 occurrences)\n",
      "    15. 'i⎵⎵' (108 occurrences)\n",
      "\n",
      " MODEL STATISTICS:\n",
      "Total languages: 13\n",
      "N-gram size: 3\n",
      "Max features per language: 300\n",
      "Total unique n-grams across all languages: 3,900\n",
      "\n",
      " N-GRAM OVERLAP ANALYSIS:\n",
      "   zh-de: 1 shared n-grams (0.2% overlap)\n",
      "   zh-en: 1 shared n-grams (0.2% overlap)\n",
      "   zh-fi: 1 shared n-grams (0.2% overlap)\n",
      "   zh-fr: 1 shared n-grams (0.2% overlap)\n",
      "   zh-it: 1 shared n-grams (0.2% overlap)\n",
      "   zh-ja: 2 shared n-grams (0.3% overlap)\n",
      "   zh-ko: 0 shared n-grams (0.0% overlap)\n",
      "   zh-pl: 1 shared n-grams (0.2% overlap)\n",
      "   zh-pt: 1 shared n-grams (0.2% overlap)\n",
      "   zh-ru: 0 shared n-grams (0.0% overlap)\n",
      "   zh-es: 1 shared n-grams (0.2% overlap)\n",
      "   zh-tr: 1 shared n-grams (0.2% overlap)\n",
      "   de-en: 101 shared n-grams (20.2% overlap)\n",
      "   de-fi: 55 shared n-grams (10.1% overlap)\n",
      "   de-fr: 96 shared n-grams (19.0% overlap)\n",
      "   de-it: 64 shared n-grams (11.9% overlap)\n",
      "   de-ja: 0 shared n-grams (0.0% overlap)\n",
      "   de-ko: 0 shared n-grams (0.0% overlap)\n",
      "   de-pl: 40 shared n-grams (7.1% overlap)\n",
      "   de-pt: 75 shared n-grams (14.3% overlap)\n",
      "   de-ru: 0 shared n-grams (0.0% overlap)\n",
      "   de-es: 82 shared n-grams (15.8% overlap)\n",
      "   de-tr: 65 shared n-grams (12.1% overlap)\n",
      "   en-fi: 49 shared n-grams (8.9% overlap)\n",
      "   en-fr: 101 shared n-grams (20.2% overlap)\n",
      "   en-it: 94 shared n-grams (18.6% overlap)\n",
      "   en-ja: 0 shared n-grams (0.0% overlap)\n",
      "   en-ko: 0 shared n-grams (0.0% overlap)\n",
      "   en-pl: 51 shared n-grams (9.3% overlap)\n",
      "   en-pt: 86 shared n-grams (16.7% overlap)\n",
      "   en-ru: 0 shared n-grams (0.0% overlap)\n",
      "   en-es: 89 shared n-grams (17.4% overlap)\n",
      "   en-tr: 51 shared n-grams (9.3% overlap)\n",
      "   fi-fr: 67 shared n-grams (12.6% overlap)\n",
      "   fi-it: 80 shared n-grams (15.4% overlap)\n",
      "   fi-ja: 0 shared n-grams (0.0% overlap)\n",
      "   fi-ko: 0 shared n-grams (0.0% overlap)\n",
      "   fi-pl: 49 shared n-grams (8.9% overlap)\n",
      "   fi-pt: 58 shared n-grams (10.7% overlap)\n",
      "   fi-ru: 0 shared n-grams (0.0% overlap)\n",
      "   fi-es: 68 shared n-grams (12.8% overlap)\n",
      "   fi-tr: 63 shared n-grams (11.7% overlap)\n",
      "   fr-it: 112 shared n-grams (23.0% overlap)\n",
      "   fr-ja: 0 shared n-grams (0.0% overlap)\n",
      "   fr-ko: 0 shared n-grams (0.0% overlap)\n",
      "   fr-pl: 48 shared n-grams (8.7% overlap)\n",
      "   fr-pt: 110 shared n-grams (22.4% overlap)\n",
      "   fr-ru: 0 shared n-grams (0.0% overlap)\n",
      "   fr-es: 123 shared n-grams (25.8% overlap)\n",
      "   fr-tr: 45 shared n-grams (8.1% overlap)\n",
      "   it-ja: 0 shared n-grams (0.0% overlap)\n",
      "   it-ko: 0 shared n-grams (0.0% overlap)\n",
      "   it-pl: 73 shared n-grams (13.9% overlap)\n",
      "   it-pt: 136 shared n-grams (29.3% overlap)\n",
      "   it-ru: 0 shared n-grams (0.0% overlap)\n",
      "   it-es: 145 shared n-grams (31.9% overlap)\n",
      "   it-tr: 57 shared n-grams (10.5% overlap)\n",
      "   ja-ko: 0 shared n-grams (0.0% overlap)\n",
      "   ja-pl: 0 shared n-grams (0.0% overlap)\n",
      "   ja-pt: 0 shared n-grams (0.0% overlap)\n",
      "   ja-ru: 0 shared n-grams (0.0% overlap)\n",
      "   ja-es: 0 shared n-grams (0.0% overlap)\n",
      "   ja-tr: 0 shared n-grams (0.0% overlap)\n",
      "   ko-pl: 0 shared n-grams (0.0% overlap)\n",
      "   ko-pt: 0 shared n-grams (0.0% overlap)\n",
      "   ko-ru: 0 shared n-grams (0.0% overlap)\n",
      "   ko-es: 0 shared n-grams (0.0% overlap)\n",
      "   ko-tr: 0 shared n-grams (0.0% overlap)\n",
      "   pl-pt: 67 shared n-grams (12.6% overlap)\n",
      "   pl-ru: 0 shared n-grams (0.0% overlap)\n",
      "   pl-es: 66 shared n-grams (12.4% overlap)\n",
      "   pl-tr: 38 shared n-grams (6.8% overlap)\n",
      "   pt-ru: 0 shared n-grams (0.0% overlap)\n",
      "   pt-es: 171 shared n-grams (39.9% overlap)\n",
      "   pt-tr: 49 shared n-grams (8.9% overlap)\n",
      "   ru-es: 0 shared n-grams (0.0% overlap)\n",
      "   ru-tr: 0 shared n-grams (0.0% overlap)\n",
      "   es-tr: 51 shared n-grams (9.3% overlap)\n"
     ]
    }
   ],
   "source": [
    "# Analyze the language profiles\n",
    "for language, profile in identifier.language_profiles.items():\n",
    "    print(f\"\\n Top 15 n-grams for {language.upper()}:\")\n",
    "    \n",
    "    # Sort by frequency and display top n-grams\n",
    "    sorted_ngrams = sorted(profile.items(), key = lambda x: x[1], reverse = True)[:15]\n",
    "    \n",
    "    for i, (ngram, freq) in enumerate(sorted_ngrams, 1):\n",
    "        # Replace underscores with ⎵ for better visualization\n",
    "        display_ngram = ngram.replace('_', '⎵')\n",
    "        print(f\"    {i:2d}. '{display_ngram}' ({freq:,} occurrences)\")\n",
    "\n",
    "# Show model statistics\n",
    "print(f\"\\n MODEL STATISTICS:\")\n",
    "print(f\"Total languages: {len(identifier.language_profiles)}\")\n",
    "print(f\"N-gram size: {identifier.n_gram_size}\")\n",
    "print(f\"Max features per language: {identifier.max_features}\")\n",
    "\n",
    "total_ngrams = sum(len(profile) for profile in identifier.language_profiles.values())\n",
    "print(f\"Total unique n-grams across all languages: {total_ngrams:,}\")\n",
    "\n",
    "# Calculate overlap between language profiles\n",
    "print(f\"\\n N-GRAM OVERLAP ANALYSIS:\")\n",
    "languages = list(identifier.language_profiles.keys())\n",
    "for i, lang1 in enumerate(languages):\n",
    "    for lang2 in languages[i+1:]:\n",
    "        set1 = set(identifier.language_profiles[lang1].keys())\n",
    "        set2 = set(identifier.language_profiles[lang2].keys())\n",
    "        overlap = len(set1.intersection(set2))\n",
    "        total_unique = len(set1.union(set2))\n",
    "        overlap_pct = (overlap / total_unique) * 100 if total_unique > 0 else 0\n",
    "        print(f\"   {lang1}-{lang2}: {overlap} shared n-grams ({overlap_pct:.1f}% overlap)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9e49e",
   "metadata": {},
   "source": [
    "## 10) Save the Trained Model\n",
    "\n",
    "To avoid retraining each time, we save the trained model as a JSON file.  \n",
    "The file includes the n-gram settings and the frequency profiles for all trained languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea202cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving trained model\n",
      "Model saved successfully!\n",
      "File: language_identification_model.json\n",
      "Size: 73.3 KB\n",
      "Languages: zh, de, en, fi, fr, it, ja, ko, pl, pt, ru, es, tr\n",
      "Total features: 3,900\n"
     ]
    }
   ],
   "source": [
    "def save_model(identifier, filepath: str):\n",
    "    if not identifier.trained:\n",
    "        raise ValueError(\"Cannot save untrained model\")\n",
    "    \n",
    "    model_data = {\n",
    "        'n_gram_size': identifier.n_gram_size,\n",
    "        'max_features': identifier.max_features,\n",
    "        'language_profiles': identifier.language_profiles,\n",
    "        'languages': list(identifier.language_profiles.keys()),\n",
    "        'total_features': sum(len(profile) for profile in identifier.language_profiles.values())\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(model_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "# Save the model\n",
    "model_file = \"language_identification_model.json\"\n",
    "print(f\"Saving trained model\")\n",
    "\n",
    "try:\n",
    "    model_info = save_model(identifier, model_file)\n",
    "    file_size = os.path.getsize(model_file) / 1024  # Size in KB\n",
    "    \n",
    "    print(f\"Model saved successfully!\")\n",
    "    print(f\"File: {model_file}\")\n",
    "    print(f\"Size: {file_size:.1f} KB\")\n",
    "    print(f\"Languages: {', '.join(model_info['languages'])}\")\n",
    "    print(f\"Total features: {model_info['total_features']:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2010f9",
   "metadata": {},
   "source": [
    "## 11) Load a Saved Model\n",
    "\n",
    "Load a previously saved model (from a JSON file).  \n",
    "You can use it in a new session without retraining everything from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "125bd973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from language_identification_model.json\n",
      "Model loaded successfully!\n",
      "Languages: zh, de, en, fi, fr, it, ja, ko, pl, pt, ru, es, tr\n",
      "Total features: 3,900\n",
      "Test result: en\n",
      "The model loading function is ready!\n"
     ]
    }
   ],
   "source": [
    "def load_saved_model(filepath: str) -> LanguageIdentifier:\n",
    "    print(f\"Loading model from {filepath}\")\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            model_data = json.load(f)\n",
    "        \n",
    "        # Create new identifier instance\n",
    "        loaded_identifier = LanguageIdentifier(\n",
    "            n_gram_size=model_data['n_gram_size'],\n",
    "            max_features=model_data['max_features']\n",
    "        )\n",
    "        \n",
    "        # Load the language profiles\n",
    "        loaded_identifier.language_profiles = model_data['language_profiles']\n",
    "        loaded_identifier.trained = True\n",
    "        \n",
    "        print(f\"Model loaded successfully!\")\n",
    "        print(f\"Languages: {', '.join(model_data.get('languages', []))}\")\n",
    "        print(f\"Total features: {model_data.get('total_features', 'Unknown'):,}\")\n",
    "        \n",
    "        return loaded_identifier\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file '{filepath}' not found!\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# load the model\n",
    "loaded_model = load_saved_model(\"language_identification_model.json\")\n",
    "if loaded_model:\n",
    "    test_text = \"This is a test sentence.\"\n",
    "    result = loaded_model.identify_language(test_text)\n",
    "    print(f\"Test result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e207a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
